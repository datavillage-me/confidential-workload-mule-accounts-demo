"""
This project provides a demo of a confidential workload to share mule accounts.
The confidential workload handles 3 events: one to trigger the data holders' data quality checks, one to trigger selection of suspicious accounts and one to trigger check if an account is confirmed mule account
"""

import logging
import time
import yaml
import os
import json
import duckdb
from datetime import datetime
import base64
import shutil

from dv_utils import default_settings, Client, ContractManager,audit_log,LogLevel

logger = logging.getLogger(__name__)

# let the log go to stdout, as it will be captured by the cage operator
logging.basicConfig(
    level=default_settings.log_level,
    format="%(asctime)s - %(levelname)s - %(message)s",
)

keys_input_dir = "/resources/data"
#keys_input_dir = "demo-keys"

# define an event processing function
def event_processor(evt: dict):
    """
    Process an incoming event
    Exception raised by this function are handled by the default event listener and reported in the logs.
    """
    
    logger.info(f"Processing event {evt}")

    # dispatch events according to their type
    evt_type =evt.get("type", "")

    if evt_type == "CHECK_DATA_QUALITY":
        # use the CHECK_DATA_QUALITY event processor dedicated function
        logger.info(f"Use the check data quality event processor")
        check_data_quality_contracts_event_processor(evt)
    else:
        generic_event_processor(evt)


def generic_event_processor(evt: dict):
    # push an audit log to reccord for an event that is not understood
    logger.info(f"Received an unhandled event {evt}")

def check_data_quality_contracts_event_processor(evt: dict):
    #audit logs are generated by the dv_utils sdk
    try:
        contractManager=ContractManager()
        test_results=contractManager.check_contracts_for_collaboration_space(default_settings.collaboration_space_id)

        #get data contracts from all data consumers
        data_contracts=contractManager.get_contracts_for_collaboration_space(default_settings.collaboration_space_id,Client.DATA_CONSUMER_COLLABORATOR_ROLE_VALUE)
        #Create in memory duckdb (encrypted memory on confidential computing)
        con = duckdb.connect(database=":memory:")
        
        #Add connector settings to duckdb con for all data contracts and export only test results linked to the right client
        #TODO need to add the client_id in a contract within a collaboration space... to be discussed with the team
        client=Client()
        participants=client.get_list_of_participants(default_settings.collaboration_space_id,None)
        model_key="quality_checks"
        for data_contract in data_contracts:
            target_id=data_contract.data_descriptor_id
            target_client_id = next(
                (item["clientId"] for item in participants if "dataDescriptors" in item and any(dd["id"] == target_id for dd in item["dataDescriptors"])),
                None
            )
            for test_result_descriptor_id in test_results:
                source_client_id = next(
                    (item["clientId"] for item in participants if "dataDescriptors" in item and any(dd["id"] == test_result_descriptor_id for dd in item["dataDescriptors"])),
                    None
                )
                if target_client_id==source_client_id:
                    con = data_contract.connector.add_duck_db_connection(con)
                    con.sql(data_contract.export_contract_to_sql_create_table(model_key))
                    check_results=test_results[test_result_descriptor_id]
                    for check_result in check_results:
                        description=check_result
                        timestamp=now = datetime.now()
                        formated_now = now.strftime('%Y-%m-%dT%H:%M:%SZ')
                        check_result_json=test_results[test_result_descriptor_id][check_result]
                        hasErrors=check_result_json["hasErrors"]
                        hasWarnings=check_result_json["hasWarnings"]
                        hasFailures=check_result_json["hasFailures"]
                        query="INSERT INTO "+model_key+" VALUES ('"+description+"','"+formated_now+"',"+str(hasErrors)+","+str(hasWarnings)+","+str(hasFailures)+",'"+str(json.dumps(check_result_json).replace("'","''"))+"')"
                        con.sql(query)
                    export_sql=data_contract.connector.export_duckdb(model_key)
                    con.sql(export_sql)  
        
    except Exception as e:
        logger.error(e)